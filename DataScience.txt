I would like to share couple of Machine Learning / Data Science facts I remind myself every-now-and-then in case it also helps someone else in their adventures:

[PART 1]
ðŸ”´ Distance between the mean and the median can not be more than 1 standard deviation (Mallows, 1991)
ðŸ”´ [ ] is faster than list( ) in python
ðŸ”´ "Matthews correlation coefficient" (neither AUC nor F1 score, definitely not accuracy) is the most proper evaluation metric for a classifier if the data is imbalanced (Boughorbel, 2017)
ðŸ”´ L2 regularization is equivalent to Gaussian prior in Bayesian sense (and L1 to Laplacian)
ðŸ”´ Backpropagation is not the only way to train a neural net. In fact, you can even train a neural net without a learning rate by betting on a coin toss (Orabona, 2017)
ðŸ”´ It is actually possible to have a trainable pooling layer in a neural net (Zhang, 2018)
ðŸ”´ Convolutional neural networks are biased towards "textures" compared to "shapes" (Geirhos, 2019)
ðŸ”´ Neural network training wastes most of the time on "easy" samples. Use Importance Sampling to sample "difficult" cases more often to speed up training (Katharopoulos, 2018)
